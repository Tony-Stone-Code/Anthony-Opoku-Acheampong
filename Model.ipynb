{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection Project\n",
    "\n",
    "This project focuses on building a machine learning model to detect fraudulent transactions. We will explore, preprocess, and model the data to classify transactions as fraud or non-fraud using a dataset of anonymized credit card transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, visualization, and modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Display settings for better visualization in notebook\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset and Basic Exploration\n",
    "\n",
    "Loading the dataset and display basic information to understand the structure and types of columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and examine basic information to understand its structure\n",
    "dataset = pd.read_csv('creditcard.csv')\n",
    "\n",
    "dataset.head()  # Display the first few rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()  # Overview of dataset structure and types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Exploration - Class Distribution\n",
    "\n",
    "Exploring the distribution of the target variable `Class` to understand class imbalance (fraud vs non-fraud).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of the target variable 'Class'\n",
    "sns.countplot(x='Class', data=dataset)\n",
    "plt.title('Distribution of Classes (Fraud vs Non-Fraud)')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the class distribution percentage\n",
    "class_distribution = dataset['Class'].value_counts(normalize=True) * 100\n",
    "print(\"Class Distribution:\\n\", class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of transactions\n",
    "dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the dataframe for fraudulent transaction \n",
    "fraud_transactions = dataset[dataset['Class'] == 1]\n",
    "# calulating the total amount of transaction \n",
    "total_fraudulent_amount = fraud_transactions['Amount'].sum()\n",
    "# printing the total amount of fraudulent transaction\n",
    "print(\"Total amount of fraudulent transaction: \", total_fraudulent_amount)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "\n",
    "Handling missing values, normalizing the `Amount` and `Time` features, and preparing the data for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values (if any) by filling with median values as the dataset is mostly numerical\n",
    "dataset = dataset.fillna(dataset.median())\n",
    "\n",
    "# Scale 'Amount' and 'Time' features since they have a different scale compared to other features\n",
    "scaler = StandardScaler()\n",
    "dataset[['Amount', 'Time']] = scaler.fit_transform(dataset[['Amount', 'Time']])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore key features such as `Amount` and `Time` to observe their distributions. We will also examine how `Amount` varies between fraud and non-fraud transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for 'Amount' and 'Time' to see their characteristics\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(dataset['Amount'], bins=100, kde=True)\n",
    "plt.title('Transaction Amount Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(dataset['Time'], bins=50, kde=True)\n",
    "plt.title('Transaction Time Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Compare 'Amount' for Fraud vs Non-Fraud\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x='Class', y='Amount', data=dataset)\n",
    "plt.title('Amount Distribution by Class')\n",
    "plt.xlabel('Class (0 = Non-Fraud, 1 = Fraud)')\n",
    "plt.ylabel('Amount')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of the target variable 'Class'\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Class', data=dataset)\n",
    "plt.title('Distribution of Classes (Fraud vs Non-Fraud)')\n",
    "plt.xlabel('Class (0 = Non-Fraud, 1 = Fraud)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the class distribution percentage\n",
    "class_distribution = dataset['Class'].value_counts(normalize=True) * 100\n",
    "print(\"Class Distribution:\\n\", class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dataset.corr()\n",
    "corr\n",
    "\n",
    "plt.figure(figsize=(24,18))\n",
    "\n",
    "sns.heatmap(corr,cmap=\"coolwarm\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Data Preparation for Modeling\n",
    "\n",
    "Splitting the data into features and target variables, then into training and test sets. Next, we handle class imbalance using SMOTE to oversample the minority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = dataset.drop('Class', axis=1)\n",
    "y = dataset\n",
    "['Class']\n",
    "\n",
    "# Split into training and testing sets (80-20 split, stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance in the training data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Building and Training\n",
    "\n",
    "Training a Random Forest classifier on the resampled data to classify transactions as fraudulent or non-fraudulent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest classifier on the resampled data\n",
    "Model = RandomForestClassifier(random_state=42)\n",
    "Model.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model Evaluation\n",
    "\n",
    "Evaluating the model using a confusion matrix, classification report, and ROC AUC score to assess its performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and probability scores on the test set\n",
    "y_pred = Model.predict(X_test)\n",
    "y_pred_prob = Model.predict_prob(X_test)[:, 1]\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, I built a Random Forest model to detect fraudulent transactions. The model achieved an ROC AUC score of X.XX, indicating its effectiveness in distinguishing fraud from non-fraud transactions. Additional improvements could be made by exploring other models and tuning hyperparameters.\n",
    "\n",
    "Future ideas in mind:\n",
    "- Try alternative models such as Gradient Boosting or XGBoost for potentially improved results as time goes on.\n",
    "- Use GridSearchCV for hyperparameter tuning to refine the Random Forest model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
